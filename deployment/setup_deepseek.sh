#!/bin/bash

# DeepSeek Backend Setup Script
# This script sets up the DeepSeek OCR backend with virtual environment and dependencies

set -e  # Exit on any error

echo "=========================================="
echo "DeepSeek OCR Backend Setup"
echo "=========================================="

# Set environment variables for compatibility
export VLLM_USE_V1=0
echo "âœ“ Set VLLM_USE_V1=0 for legacy API compatibility"

# Create DeepSeek virtual environment
echo "ðŸ“¦ Creating DeepSeek virtual environment..."
python3 -m venv ../backends/deepseek-ocr/venv
source ../backends/deepseek-ocr/venv/bin/activate

# Install dependencies
echo "ðŸ“¦ Installing DeepSeek dependencies..."
pip install --upgrade pip

# Install uv for better dependency management
echo "Installing uv for package management..."
pip install uv

# Install vLLM with automatic PyTorch backend selection (recommended approach)
echo "Installing vLLM with automatic PyTorch backend selection..."
uv pip install vllm==0.8.5 --torch-backend=auto

# Force correct NumPy version (required by DeepSeek-OCR)
echo "Installing NumPy 1.26.4 (required version)..."
uv pip install numpy==1.26.4

# Install required packages from official DeepSeek-OCR requirements
echo "Installing required packages from official requirements..."
uv pip install transformers==4.46.3 tokenizers==0.20.3
uv pip install PyMuPDF img2pdf einops easydict addict Pillow

# Install server dependencies
echo "Installing server dependencies..."
uv pip install flask flask-cors

# Install optional packages (may fail on some systems)
echo "Installing optional packages..."
uv pip install matplotlib || echo "âš  matplotlib installation failed (optional)"

# Install flash-attn (MUST HAVE for optimal performance)
echo "ðŸš€ Installing flash-attn (MUST HAVE for optimal performance)..."

# Detect CUDA Toolkit installation
echo "ðŸ” Checking CUDA Toolkit installation..."

# Check multiple possible CUDA installation locations
CUDA_PATHS="/usr/local/cuda-12.1 /usr/local/cuda /opt/cuda"
CUDA_HOME=""

for path in $CUDA_PATHS; do
    if [ -d "$path" ] && [ -f "$path/bin/nvcc" ]; then
        CUDA_HOME="$path"
        echo "âœ… CUDA Toolkit found at: $CUDA_HOME"
        break
    fi

    # Also check if nvcc is in PATH
    if command -v nvcc >/dev/null 2>&1; then
        CUDA_HOME=$(dirname $(dirname $(which nvcc)))
        echo "âœ… CUDA Toolkit found via PATH at: $CUDA_HOME"
        break
    fi
done

if [ -n "$CUDA_HOME" ]; then
    export CUDA_HOME
    export PATH=$CUDA_HOME/bin:$PATH
    export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
else
    echo "âŒ CUDA Toolkit not found. Installing CUDA 12.1 (compatible with flash-attn)..."

    # Check if CUDA installer already exists to avoid re-downloading
    if [ ! -f "cuda_12.1.0_530.30.02_linux.run" ]; then
        wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run
    fi

    chmod +x cuda_12.1.0_530.30.02_linux.run
    sudo ./cuda_12.1.0_530.30.02_linux.run --silent --toolkit --override

    export CUDA_HOME=/usr/local/cuda-12.1
    export PATH=$CUDA_HOME/bin:$PATH
    export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

    echo "âœ… CUDA Toolkit 12.1 installed at: $CUDA_HOME"
fi

# Install wheel first (required for flash-attn build but not declared as dependency)
uv pip install wheel
echo "Installing flash-attn with CUDA support..."

# Install flash-attn with CUDA Toolkit - NO FALLBACKS, NO PRE-BUILT WHEELS
uv pip install flash-attn --no-build-isolation

# Download DeepSeek OCR model with parallel downloads and progress tracking
echo "ðŸ“¥ Downloading DeepSeek OCR model (parallel download with progress)..."
MODEL_DIR="../models/deepseek-ocr"
mkdir -p "$MODEL_DIR"

# Download using huggingface_hub with detailed progress tracking
echo "Downloading model from HuggingFace with progress tracking..."

# Use Python script with detailed progress tracking
python3 -c "
import os
import time
from huggingface_hub import snapshot_download, list_repo_files
from huggingface_hub.utils import tqdm

MODEL_DIR = '$MODEL_DIR'
REPO_ID = 'deepseek-ai/DeepSeek-OCR'

# Get list of files to download
print('ðŸ“‹ Getting file list...')
files = list_repo_files(REPO_ID)
print(f'ðŸ“ Found {len(files)} files to download')

# Track downloaded files
downloaded_files = []

def progress_callback(downloaded, total):
    if total > 0:
        percentage = (downloaded / total) * 100
        print(f'ðŸ“¥ Progress: {downloaded}/{total} files ({percentage:.1f}%)', end='\r')

# Download with progress tracking
print('ðŸš€ Starting download...')
snapshot_download(
    repo_id=REPO_ID,
    local_dir=MODEL_DIR,
    local_dir_use_symlinks=False,
    force_download=False,
    max_workers=4
)

print('')
print('âœ… Model download completed successfully!')
print(f'ðŸ“¦ Downloaded {len(files)} files to {MODEL_DIR}')
"

# Verify installations
echo "Verifying installations..."
python -c "import numpy; print(f'âœ“ NumPy: {numpy.__version__}')"
python -c "import vllm; print(f'âœ“ vLLM: {vllm.__version__}')"
python -c "import transformers; print(f'âœ“ Transformers: {transformers.__version__}')"
python -c "import torch; print(f'âœ“ PyTorch: {torch.__version__}')"
python -c "import flask; print(f'âœ“ Flask: {flask.__version__}')"

echo ""
echo "=========================================="
echo "âœ… DeepSeek backend setup completed!"
echo "=========================================="
echo "   Virtual environment: ../backends/deepseek-ocr/venv"
echo "   Model directory: $MODEL_DIR"
echo "   Server port: 5000"
echo "   GPU: 0 (CUDA_VISIBLE_DEVICES=0)"
echo ""
echo "Next steps:"
echo "   1. Activate environment: source ../backends/deepseek-ocr/venv/bin/activate"
echo "   2. Start server: python ../backends/deepseek-ocr/server.py"
echo "   3. Test: curl http://localhost:5000/health"
echo ""
echo "Compatible GPU architectures: sm_50, sm_60, sm_70, sm_75, sm_80, sm_86, sm_89, sm_90"
echo "Incompatible: sm_120 (RTX 5080)"
echo "=========================================="